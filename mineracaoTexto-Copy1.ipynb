{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e923e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'mineracaoTexto-Copy1.ipynb', 'mineracaoTexto.ipynb', 'Tweets_Mg.csv', 'tweets_teste01.csv']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# Os arquivos de dados de entrada estão disponíveis no diretório \"../input/\".\n",
    "# Por exemplo, executar isso (clicando em executar ou pressionando Shift+Enter) listará os arquivos no diretório de entrada\n",
    "\n",
    "#from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"-l\", \"C:\\Users\\maria.oliveira\\Documents\\workspace\\projetos\\listas Ia\"]).decode(\"utf8\"))\n",
    "\n",
    "import os\n",
    "l = os.listdir(\"C:\\\\Users\\\\maria.oliveira\\\\Documents\\\\workspace\\\\projetos\\\\listas Ia\")\n",
    "print (l)\n",
    "\n",
    "# Quaisquer resultados que você gravar no diretório atual são salvos como saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e17155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   8199\n",
       "Created At                   8199\n",
       "Text                         8199\n",
       "Geo Coordinates.latitude      104\n",
       "Geo Coordinates.longitude     104\n",
       "User Location                5489\n",
       "Username                     8199\n",
       "User Screen Name             8199\n",
       "Retweet Count                8199\n",
       "Classificacao                8199\n",
       "Observação                      1\n",
       "Unnamed: 10                     0\n",
       "Unnamed: 11                     0\n",
       "Unnamed: 12                     0\n",
       "Unnamed: 13                     0\n",
       "Unnamed: 14                     0\n",
       "Unnamed: 15                     0\n",
       "Unnamed: 16                     0\n",
       "Unnamed: 17                     0\n",
       "Unnamed: 18                     0\n",
       "Unnamed: 19                     0\n",
       "Unnamed: 20                     0\n",
       "Unnamed: 21                     0\n",
       "Unnamed: 22                     0\n",
       "Unnamed: 23                     0\n",
       "Unnamed: 24                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeiro, vamos contar a quantidade total de registros\n",
    "dataset = pd.read_csv('C:\\\\Users\\\\maria.oliveira\\\\Documents\\\\workspace\\\\projetos\\\\listas Ia\\\\Tweets_Mg.csv',encoding='utf-8')\n",
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39df45f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   2453\n",
       "Created At                   2453\n",
       "Text                         2453\n",
       "Geo Coordinates.latitude      102\n",
       "Geo Coordinates.longitude     102\n",
       "User Location                1712\n",
       "Username                     2453\n",
       "User Screen Name             2453\n",
       "Retweet Count                2453\n",
       "Classificacao                2453\n",
       "Observação                      0\n",
       "Unnamed: 10                     0\n",
       "Unnamed: 11                     0\n",
       "Unnamed: 12                     0\n",
       "Unnamed: 13                     0\n",
       "Unnamed: 14                     0\n",
       "Unnamed: 15                     0\n",
       "Unnamed: 16                     0\n",
       "Unnamed: 17                     0\n",
       "Unnamed: 18                     0\n",
       "Unnamed: 19                     0\n",
       "Unnamed: 20                     0\n",
       "Unnamed: 21                     0\n",
       "Unnamed: 22                     0\n",
       "Unnamed: 23                     0\n",
       "Unnamed: 24                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora, apenas os classificados como neutro\n",
    "dataset[dataset.Classificacao == 'Neutro'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e22d5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   3300\n",
       "Created At                   3300\n",
       "Text                         3300\n",
       "Geo Coordinates.latitude        1\n",
       "Geo Coordinates.longitude       1\n",
       "User Location                2118\n",
       "Username                     3300\n",
       "User Screen Name             3300\n",
       "Retweet Count                3300\n",
       "Classificacao                3300\n",
       "Observação                      1\n",
       "Unnamed: 10                     0\n",
       "Unnamed: 11                     0\n",
       "Unnamed: 12                     0\n",
       "Unnamed: 13                     0\n",
       "Unnamed: 14                     0\n",
       "Unnamed: 15                     0\n",
       "Unnamed: 16                     0\n",
       "Unnamed: 17                     0\n",
       "Unnamed: 18                     0\n",
       "Unnamed: 19                     0\n",
       "Unnamed: 20                     0\n",
       "Unnamed: 21                     0\n",
       "Unnamed: 22                     0\n",
       "Unnamed: 23                     0\n",
       "Unnamed: 24                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Os classificados como positivo\n",
    "dataset[dataset.Classificacao == 'Positivo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76262597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   2446\n",
       "Created At                   2446\n",
       "Text                         2446\n",
       "Geo Coordinates.latitude        1\n",
       "Geo Coordinates.longitude       1\n",
       "User Location                1659\n",
       "Username                     2446\n",
       "User Screen Name             2446\n",
       "Retweet Count                2446\n",
       "Classificacao                2446\n",
       "Observação                      0\n",
       "Unnamed: 10                     0\n",
       "Unnamed: 11                     0\n",
       "Unnamed: 12                     0\n",
       "Unnamed: 13                     0\n",
       "Unnamed: 14                     0\n",
       "Unnamed: 15                     0\n",
       "Unnamed: 16                     0\n",
       "Unnamed: 17                     0\n",
       "Unnamed: 18                     0\n",
       "Unnamed: 19                     0\n",
       "Unnamed: 20                     0\n",
       "Unnamed: 21                     0\n",
       "Unnamed: 22                     0\n",
       "Unnamed: 23                     0\n",
       "Unnamed: 24                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E finalmente, os classificados como negativo\n",
    "dataset[dataset.Classificacao == 'Negativo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f27a8274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Text</th>\n",
       "      <th>Geo Coordinates.latitude</th>\n",
       "      <th>Geo Coordinates.longitude</th>\n",
       "      <th>User Location</th>\n",
       "      <th>Username</th>\n",
       "      <th>User Screen Name</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Classificacao</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jan 08 01:22:05 +0000 2017</td>\n",
       "      <td>���⛪ @ Catedral de Santo Antônio - Governador ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>Leonardo C Schneider</td>\n",
       "      <td>LeoCSchneider</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sun Jan 08 01:49:01 +0000 2017</td>\n",
       "      <td>� @ Governador Valadares, Minas Gerais https:/...</td>\n",
       "      <td>-41.9333</td>\n",
       "      <td>-18.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wândell</td>\n",
       "      <td>klefnews</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sun Jan 08 01:01:46 +0000 2017</td>\n",
       "      <td>�� @ Governador Valadares, Minas Gerais https:...</td>\n",
       "      <td>-41.9333</td>\n",
       "      <td>-18.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wândell</td>\n",
       "      <td>klefnews</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wed Jan 04 21:43:51 +0000 2017</td>\n",
       "      <td>��� https://t.co/BnDsO34qK0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ana estudando</td>\n",
       "      <td>estudandoconcur</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon Jan 09 15:08:21 +0000 2017</td>\n",
       "      <td>��� PSOL vai questionar aumento de vereadores ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Milly777</td>\n",
       "      <td>0</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      Created At  \\\n",
       "0           0  Sun Jan 08 01:22:05 +0000 2017   \n",
       "1           1  Sun Jan 08 01:49:01 +0000 2017   \n",
       "2           2  Sun Jan 08 01:01:46 +0000 2017   \n",
       "3           3  Wed Jan 04 21:43:51 +0000 2017   \n",
       "4           4  Mon Jan 09 15:08:21 +0000 2017   \n",
       "\n",
       "                                                Text  \\\n",
       "0  ���⛪ @ Catedral de Santo Antônio - Governador ...   \n",
       "1  � @ Governador Valadares, Minas Gerais https:/...   \n",
       "2  �� @ Governador Valadares, Minas Gerais https:...   \n",
       "3                        ��� https://t.co/BnDsO34qK0   \n",
       "4  ��� PSOL vai questionar aumento de vereadores ...   \n",
       "\n",
       "   Geo Coordinates.latitude  Geo Coordinates.longitude User Location  \\\n",
       "0                       NaN                        NaN        Brasil   \n",
       "1                  -41.9333                     -18.85           NaN   \n",
       "2                  -41.9333                     -18.85           NaN   \n",
       "3                       NaN                        NaN           NaN   \n",
       "4                       NaN                        NaN           NaN   \n",
       "\n",
       "               Username User Screen Name  Retweet Count Classificacao  ...  \\\n",
       "0  Leonardo C Schneider    LeoCSchneider              0        Neutro  ...   \n",
       "1               Wândell         klefnews              0        Neutro  ...   \n",
       "2               Wândell         klefnews              0        Neutro  ...   \n",
       "3         Ana estudando  estudandoconcur              0        Neutro  ...   \n",
       "4                 Emily         Milly777              0      Negativo  ...   \n",
       "\n",
       "  Unnamed: 15  Unnamed: 16  Unnamed: 17  Unnamed: 18  Unnamed: 19  \\\n",
       "0         NaN          NaN          NaN          NaN          NaN   \n",
       "1         NaN          NaN          NaN          NaN          NaN   \n",
       "2         NaN          NaN          NaN          NaN          NaN   \n",
       "3         NaN          NaN          NaN          NaN          NaN   \n",
       "4         NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 20  Unnamed: 21  Unnamed: 22  Unnamed: 23  Unnamed: 24  \n",
       "0          NaN          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OK, vamos dar uma olhada rápida no conteúdo do dataset para finalizar esse passo\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2599d5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['���⛪ @ Catedral de Santo Antônio - Governador Valadares/MG https://t.co/JSbKamIqUJ',\n",
       "       '� @ Governador Valadares, Minas Gerais https://t.co/B3ThIDJCSf',\n",
       "       '�� @ Governador Valadares, Minas Gerais https://t.co/dPkgzVR2Qw',\n",
       "       ...,\n",
       "       'Trio é preso suspeito de roubo, tráfico e abuso sexual em Uberlândia https://t.co/zaQbXRRJWc',\n",
       "       'Trio é preso suspeito de roubo, tráfico e abuso sexual em Uberlândia: Um dos autores teria molestado vítima de… https://t.co/lQ8cTSNftA',\n",
       "       'Trio suspeito de roubo de cargas é preso em Santa Luzia (MG) https://t.co/0INgJcMtZb #R7MG #RecordTVMinas'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Próximo passo, vamos separar os tweets e suas classes\n",
    "tweets = dataset[\"Text\"].values\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "197cab51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Neutro', ..., 'Positivo', 'Positivo',\n",
       "       'Positivo'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = dataset[\"Classificacao\"].values\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acbf636c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agora, vamos treinar o modelo usando a abordagem Bag of Words e o algoritmo Naive Bayes Multinomial\n",
    "#    - Bag of Words, na prática, cria um vetor com cada uma das palavras do texto completo da base,\n",
    "#      depois, calcula a frequência em que essas palavras ocorrem em uma data sentença, para então\n",
    "#      classificar/treinar o modelo\n",
    "#    - Exemplo HIPOTÉTICO de três sentenças vetorizadas \"por palavra\" e classificadas baseada na\n",
    "#      frequência de suas palavras:\n",
    "#         {0,3,2,0,0,1,0,0,0,1, Positivo}\n",
    "#         {0,0,1,0,0,1,0,1,0,0, Negativo}\n",
    "#         {0,1,1,0,0,1,0,0,0,0, Neutro}\n",
    "#    - Olhando para esses vetores, meu palpite é que as palavras nas posições 2 e 3 são as com maior\n",
    "#      peso na determinação de a que classe pertence cada uma das três sentenças avaliadas\n",
    "#    - A função fit_transform faz exatamente esse processo: ajusta o modelo, aprende o vocabulário,\n",
    "#      e transforma os dados de treinamento em feature vectors, a.k.a. vetor com frequêcia das palavras\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\")\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "270659ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Negativo', 'Negativo', 'Neutro', 'Positivo'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos usar algumas frases de teste para fazer a classificação com o modelo treinado\n",
    "testes = [\"Esse governo está no início, vamos ver o que vai dar\",\n",
    "          \"Estou muito feliz com o governo de São Paulo esse ano\",\n",
    "          \"O estado de Minas Gerais decretou calamidade financeira!!!\",\n",
    "          \"A segurança desse país está deixando a desejar\",\n",
    "          \"O governador de Minas é do PT\",\n",
    "          \"O prefeito de São Paulo está fazendo um ótimo trabalho\"]\n",
    "\n",
    "freq_testes = vectorizer.transform(testes)\n",
    "modelo.predict(freq_testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "093ab01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Neutro', ..., 'Positivo', 'Positivo',\n",
       "       'Positivo'], dtype='<U8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validação cruzada do modelo. Neste caso, o modelo é dividido em 10 partes, treinado em 9 e testado em 1\n",
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "171ddac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831564824978656"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quão acurada é a média do modelo?\n",
    "metrics.accuracy_score(classes, resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b789585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.89      0.93      0.91      2446\n",
      "      Neutro       0.80      0.84      0.82      2453\n",
      "    Positivo       0.95      0.88      0.91      3300\n",
      "\n",
      "    accuracy                           0.88      8199\n",
      "   macro avg       0.88      0.88      0.88      8199\n",
      "weighted avg       0.89      0.88      0.88      8199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Medidas de validação do modelo\n",
    "sentimentos = [\"Positivo\", \"Negativo\", \"Neutro\"]\n",
    "print(metrics.classification_report(classes, resultados))\n",
    "\n",
    "# Lembrando que:\n",
    "#    : precision = true positive / (true positive + false positive)\n",
    "#    : recall    = true positive / (true positive + false negative)\n",
    "#    : f1-score  = 2 * ((precision * recall) / (precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea8d097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   Negativo  Neutro  Positivo   All\n",
      "Real                                      \n",
      "Negativo      2275     162         9  2446\n",
      "Neutro         240    2067       146  2453\n",
      "Positivo        45     356      2899  3300\n",
      "All           2560    2585      3054  8199\n"
     ]
    }
   ],
   "source": [
    "#Vamos fazer uma matriz de confusão -- What?!?!\n",
    "print(pd.crosstab(classes, resultados, rownames = [\"Real\"], colnames=[\"Predito\"], margins=True))\n",
    "\n",
    "# Lembrando que:\n",
    "#    - Predito = O que o programa classificou como Negativo, Neutro, Positivo e All\n",
    "#    - Real    = O que é de fato Negativo, Neutro, Positivo e All\n",
    "#\n",
    "# Ou seja, somente 9 tweets eram de fato negativos e o programa classificou como positivos. Já os\n",
    "# positivos que o programa classificou como negativos foram 45, muito mais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "124a4aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Com o modelo de Bigrams, em lugar de vetorizar o texto \"por palavra\", vamos vetoriza-lo por cada\n",
    "# \"duas palavras\", tipo: Eu gosto de São Paulo => { eu gosto, gosto de, de são, são paulo }\n",
    "vectorizer = CountVectorizer(ngram_range = (1, 8))\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd2c718d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Neutro', ..., 'Positivo', 'Positivo',\n",
       "       'Positivo'], dtype='<U8')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nova predição bigramada\n",
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv = 150)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f18ec80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9408464446883766"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qual foi a acuracidade desse novo modelo?\n",
    "metrics.accuracy_score(classes, resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78e77813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.95      0.95      0.95      2446\n",
      "      Neutro       0.88      0.94      0.91      2453\n",
      "    Positivo       0.99      0.94      0.96      3300\n",
      "\n",
      "    accuracy                           0.94      8199\n",
      "   macro avg       0.94      0.94      0.94      8199\n",
      "weighted avg       0.94      0.94      0.94      8199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As novas medidas de validação do modelo, um pouquinho melhor que o anterior\n",
    "print(metrics.classification_report(classes, resultados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f577ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   Negativo  Neutro  Positivo   All\n",
      "Real                                      \n",
      "Negativo      2315     129         2  2446\n",
      "Neutro          97    2311        45  2453\n",
      "Positivo        19     193      3088  3300\n",
      "All           2431    2633      3135  8199\n"
     ]
    }
   ],
   "source": [
    "# E a nova matriz de confusão\n",
    "print(pd.crosstab(classes, resultados, rownames = [\"Real\"], colnames = [\"Predito\"], margins = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55622195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8199x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 120891 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos reinicializar nosso bag of words com um parâmetro de máximo de features\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None,\n",
    "                             stop_words = None, max_features = 5000)\n",
    "\n",
    "# Treinar o modelo, aprender o vocabulário e transformar nossos dados de treinamento em feature vectors\n",
    "train_data_features = vectorizer.fit_transform(tweets)\n",
    "train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53b976df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hora de iniciar um classificador Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7de46e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Neutro', ..., 'Positivo', 'Positivo',\n",
       "       'Positivo'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar os sentimentos do dataset de tweets\n",
    "class_sentimentos = dataset[\"Classificacao\"].values\n",
    "class_sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f3caf9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajusta a forest ao dataset de treinamento usando a bag of words como feature e os sentimentos\n",
    "# como a resposta variável\n",
    "forest = forest.fit(train_data_features, class_sentimentos)\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1514837b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 45 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar a bag of words de teste\n",
    "test_data_features = vectorizer.transform(testes)\n",
    "test_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a73a220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutro', 'Neutro', 'Negativo', 'Neutro', 'Negativo', 'Neutro'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazer um predição\n",
    "resultados = forest.predict(test_data_features)\n",
    "resultados\n",
    "\n",
    "# Resultado que tivemos com o primeiro modelo:\n",
    "# array(['Neutro', 'Neutro', 'Negativo', 'Negativo', 'Neutro', 'Positivo'], dtype='<U8')\n",
    "#\n",
    "# Meh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2ec28fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Esse governo está no início, vamos ver o que v...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Estou muito feliz com o governo de São Paulo e...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>O estado de Minas Gerais decretou calamidade f...</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A segurança desse país está deixando a desejar</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>O governador de Minas é do PT</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>O prefeito de São Paulo está fazendo um ótimo ...</td>\n",
       "      <td>Neutro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              texto sentimento\n",
       "0   1  Esse governo está no início, vamos ver o que v...     Neutro\n",
       "1   2  Estou muito feliz com o governo de São Paulo e...     Neutro\n",
       "2   3  O estado de Minas Gerais decretou calamidade f...   Negativo\n",
       "3   4     A segurança desse país está deixando a desejar     Neutro\n",
       "4   5                      O governador de Minas é do PT   Negativo\n",
       "5   6  O prefeito de São Paulo está fazendo um ótimo ...     Neutro"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Que tal gerar uma tabelinha Pandas?\n",
    "testes_id = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "data_frame = pd.DataFrame(data = { \"id\": testes_id, \"texto\": testes, \"sentimento\": resultados })\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fed85369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'mineracaoTexto-Copy1.ipynb', 'mineracaoTexto.ipynb', 'Tweets_Mg.csv', 'tweets_teste01.csv', 'tweets_teste02.csv']\n"
     ]
    }
   ],
   "source": [
    "# E finalmente, vamos salvar nossa predição em um .csv\n",
    "data_frame.to_csv(\"tweets_teste02.csv\", index = False, quoting = 3, escapechar = \"\\\\\")\n",
    "l = os.listdir(\"C:\\\\Users\\\\maria.oliveira\\\\Documents\\\\workspace\\\\projetos\\\\listas Ia\")\n",
    "print (l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1bad3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, ok, vamos dar só mais uma espiada para ver se deu tudo certo\n",
    "#print(check_output([\"cat\", \"tweets_classificados_por_forest.csv\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f503019e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
